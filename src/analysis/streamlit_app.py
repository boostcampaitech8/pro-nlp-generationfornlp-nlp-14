import ast
from pathlib import Path

import altair as alt
import pandas as pd
import streamlit as st


def get_csv_files(directory: str) -> list[str]:
    """ì§€ì •ëœ ë””ë ‰í† ë¦¬ì—ì„œ CSV íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•œë‹¤."""
    dir_path = Path(directory)
    if not dir_path.exists():
        return []
    csv_files = sorted(dir_path.glob("*.csv"))
    return [str(f) for f in csv_files]


@st.cache_data
def load_data(data_path: str, output_path: str):
    """Load and cache data from CSV files."""
    try:
        train_df = pd.read_csv(data_path)
        output_df = pd.read_csv(output_path)
        return train_df, output_df, None
    except Exception as e:
        return None, None, str(e)


def parse_problem(problem_str: str) -> dict:
    """Parse the problem string into a dictionary."""
    try:
        return ast.literal_eval(problem_str)
    except (ValueError, SyntaxError):
        return {}


def preprocess_data(train_df: pd.DataFrame, output_df: pd.DataFrame) -> pd.DataFrame:
    """Merge and preprocess the dataframes."""
    merged_df = pd.merge(train_df, output_df, on="id", suffixes=("_source", "_pred"))

    if "problems" in merged_df.columns:
        parsed_problems = merged_df["problems"].apply(parse_problem)
        merged_df["question"] = parsed_problems.apply(lambda x: x.get("question"))
        merged_df["choices"] = parsed_problems.apply(lambda x: x.get("choices"))
        merged_df["correct_answer"] = parsed_problems.apply(lambda x: x.get("answer"))

        def check_correct(row):
            try:
                # ëª¨ë¸ ì˜ˆì¸¡ê°’ì€ answer_pred ì»¬ëŸ¼ì— ìˆìŒ
                pred_answer = (
                    row.get("answer_pred")
                    if "answer_pred" in row
                    else row.get("answer")
                )
                return int(row["correct_answer"]) == int(pred_answer)
            except (ValueError, TypeError):
                return False

        merged_df["is_correct"] = merged_df.apply(check_correct, axis=1)

        # ì˜ˆì¸¡ê°’ì„ answer ì»¬ëŸ¼ìœ¼ë¡œ í†µì¼ (ë‚˜ë¨¸ì§€ ì½”ë“œ í˜¸í™˜ì„± ìœ ì§€)
        if "answer_pred" in merged_df.columns:
            merged_df["answer"] = merged_df["answer_pred"]

        # Calculate input length
        def calc_len(row):
            p_len = len(str(row.get("paragraph", "")))
            q_len = len(str(row.get("question", "")))
            c_len = sum(len(str(c)) for c in row.get("choices", []))
            return p_len + q_len + c_len

        merged_df["input_length"] = merged_df.apply(calc_len, axis=1)

    return merged_df


def main():
    st.set_page_config(layout="wide", page_title="ëª¨ë¸ ì˜¤ë‹µ ë¶„ì„")
    st.title("ğŸ¯ ëª¨ë¸ ì˜¤ë‹µ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

    # ==========================================
    # ì‚¬ì´ë“œë°”: ì„¤ì • ë° í•„í„°
    # ==========================================
    st.sidebar.header("âš™ï¸ ì„¤ì • (Configuration)")

    # data/ ë””ë ‰í† ë¦¬ì˜ CSV íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    data_files = get_csv_files("data/fold")
    if data_files:
        data_path = st.sidebar.selectbox(
            "ë°ì´í„° ê²½ë¡œ (CSV)",
            options=data_files,
            index=0,
        )
    else:
        st.sidebar.warning("data/fold/ ë””ë ‰í† ë¦¬ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        data_path = st.sidebar.text_input(
            "ë°ì´í„° ê²½ë¡œ (CSV)", "data/fold/train_with_folds.csv"
        )

    # outputs/ ë””ë ‰í† ë¦¬ì˜ CSV íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    output_files = get_csv_files("outputs")
    if output_files:
        output_path = st.sidebar.selectbox(
            "ëª¨ë¸ 1 ì¶œë ¥ ê²½ë¡œ (CSV)",
            options=output_files,
            index=0,
        )
    else:
        st.sidebar.warning("outputs/ ë””ë ‰í† ë¦¬ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        output_path = st.sidebar.text_input(
            "ëª¨ë¸ 1 ì¶œë ¥ ê²½ë¡œ (CSV)", "outputs/output.csv"
        )

    # Multi-model comparison
    with st.sidebar.expander("ğŸ”„ ëª¨ë¸ ë¹„êµ (ì„ íƒì‚¬í•­)"):
        enable_comparison = st.checkbox("ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë¹„êµ")
        if enable_comparison:
            if output_files:
                output_path_2 = st.selectbox(
                    "ëª¨ë¸ 2 ì¶œë ¥ ê²½ë¡œ (CSV)",
                    options=output_files,
                    index=min(
                        1, len(output_files) - 1
                    ),  # ë‘ ë²ˆì§¸ íŒŒì¼ ë˜ëŠ” ì²« ë²ˆì§¸ íŒŒì¼
                    key="output_path_2",
                )
            else:
                output_path_2 = st.text_input(
                    "ëª¨ë¸ 2 ì¶œë ¥ ê²½ë¡œ (CSV)", "outputs/model2.csv"
                )
        else:
            output_path_2 = None

    if st.sidebar.button("ë°ì´í„° ë¡œë“œ (Load Data)", type="primary"):
        st.session_state["load_data"] = True

    if not st.session_state.get("load_data", False):
        st.info("ğŸ‘ˆ ê²½ë¡œë¥¼ í™•ì¸í•˜ê³  'ë°ì´í„° ë¡œë“œ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        return

    # Load data with caching
    with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
        train_df, output_df, error = load_data(data_path, output_path)

    if error:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {error}")
        return

    if train_df is None or output_df is None:
        st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # Merge and preprocess
    try:
        merged_df = preprocess_data(train_df, output_df)
    except KeyError as e:
        st.error(f"ë³‘í•© ì‹¤íŒ¨: {e}. ë‘ CSV íŒŒì¼ ëª¨ë‘ 'id' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        return
    except Exception as e:
        st.error(f"ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return

    if "is_correct" not in merged_df.columns:
        st.error("ë°ì´í„° íŒŒì¼ì— 'problems' ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    # Load second model for comparison if enabled
    merged_df_2 = None
    if enable_comparison and output_path_2:
        try:
            output_df_2 = pd.read_csv(output_path_2)
            merged_df_2 = pd.merge(
                train_df, output_df_2, on="id", suffixes=("", "_pred2")
            )
            if "problems" in merged_df_2.columns:
                parsed_problems_2 = merged_df_2["problems"].apply(parse_problem)
                merged_df_2["correct_answer"] = parsed_problems_2.apply(
                    lambda x: x.get("answer")
                )
                merged_df_2["is_correct_2"] = merged_df_2.apply(
                    lambda row: int(row["correct_answer"]) == int(row["answer"])
                    if pd.notna(row["correct_answer"]) and pd.notna(row["answer"])
                    else False,
                    axis=1,
                )
        except Exception as e:
            st.sidebar.warning(f"ëª¨ë¸ 2 ë¡œë“œ ì‹¤íŒ¨: {e}")
            merged_df_2 = None

    # ------------------------------------------
    # ë™ì  í•„í„° ìƒì„± (ì‚¬ì´ë“œë°”)
    # ------------------------------------------
    st.sidebar.header("ğŸ” í•„í„° (Filters)")

    ignore_cols = [
        "id",
        "paragraph",
        "problems",
        "question_plus",
        "question",
        "choices",
        "correct_answer",
        "answer",
        "is_correct",
        "input_length",
    ]
    potential_cats = [
        col
        for col in merged_df.columns
        if col not in ignore_cols and merged_df[col].nunique() < 50
    ]

    active_filters = {}
    if potential_cats:
        for col in potential_cats:
            options = sorted(merged_df[col].unique().tolist())

            with st.sidebar.expander(f"ğŸ“ {col}", expanded=False):
                # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                if f"filter_{col}" not in st.session_state:
                    st.session_state[f"filter_{col}"] = {opt: True for opt in options}

                # ì²´í¬ë°•ìŠ¤ ìƒì„±
                selected = []
                for opt in options:
                    is_checked = st.checkbox(
                        str(opt),
                        value=st.session_state[f"filter_{col}"].get(opt, True),
                        key=f"cb_{col}_{opt}",
                    )
                    st.session_state[f"filter_{col}"][opt] = is_checked
                    if is_checked:
                        selected.append(opt)

                active_filters[col] = selected

    # í•„í„° ì ìš©
    filtered_df = merged_df.copy()
    for col, selected in active_filters.items():
        filtered_df = filtered_df[filtered_df[col].isin(selected)]

    # íƒ­ êµ¬ì„±
    if enable_comparison and merged_df_2 is not None:
        tab_comprehensive, tab_error_analysis, tab_comparison = st.tabs(
            ["ğŸ“Š ì¢…í•© ë¶„ì„", "âŒ ëª¨ë¸ ì˜¤ë‹µ ë¶„ì„", "ğŸ”„ ëª¨ë¸ ë¹„êµ"]
        )
    else:
        tab_comprehensive, tab_error_analysis = st.tabs(
            ["ğŸ“Š ì¢…í•© ë¶„ì„", "âŒ ëª¨ë¸ ì˜¤ë‹µ ë¶„ì„"]
        )

    # ==========================================
    # íƒ­ 1: ì¢…í•© ë¶„ì„
    # ==========================================
    with tab_comprehensive:
        st.header("ì¢…í•© ì§€í‘œ")

        total_count = len(filtered_df)
        correct_count = filtered_df["is_correct"].sum()
        error_count = total_count - correct_count
        accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0

        # Calculate Macro F1
        def calculate_macro_f1(df):
            if "correct_answer" not in df.columns or "answer" not in df.columns:
                return 0.0, {}

            classes = sorted(
                set(df["correct_answer"].unique()) | set(df["answer"].unique())
            )
            class_metrics = {}

            for cls in classes:
                tp = len(df[(df["correct_answer"] == cls) & (df["answer"] == cls)])
                fp = len(df[(df["correct_answer"] != cls) & (df["answer"] == cls)])
                fn = len(df[(df["correct_answer"] == cls) & (df["answer"] != cls)])

                precision = tp / (tp + fp) if (tp + fp) > 0 else 0
                recall = tp / (tp + fn) if (tp + fn) > 0 else 0
                f1 = (
                    2 * precision * recall / (precision + recall)
                    if (precision + recall) > 0
                    else 0
                )

                class_metrics[cls] = {
                    "precision": precision,
                    "recall": recall,
                    "f1": f1,
                    "support": tp + fn,
                }

            macro_f1 = (
                sum(m["f1"] for m in class_metrics.values()) / len(classes)
                if classes
                else 0
            )
            return macro_f1, class_metrics

        macro_f1, class_metrics = calculate_macro_f1(filtered_df)

        col1, col2, col3, col4, col5 = st.columns(5)
        col1.metric("ğŸ“ ì„ íƒëœ ë¬¸í•­ ìˆ˜", f"{total_count}ê°œ")
        col2.metric("âœ… ì •ë‹µ ê°œìˆ˜", f"{correct_count}ê°œ")
        col3.metric("âŒ ì˜¤ë‹µ ê°œìˆ˜", f"{error_count}ê°œ")
        col4.metric("ğŸ¯ ì •í™•ë„", f"{accuracy:.2f}%")
        col5.metric("ğŸ“Š Macro F1", f"{macro_f1:.4f}")

        # Per-class metrics table (combined with answer distribution)
        st.subheader("ğŸ“ˆ ì„ íƒì§€ë³„ ë¶„í¬ ë° ì„±ëŠ¥ ì§€í‘œ")
        if class_metrics and "correct_answer" in filtered_df.columns:
            ans_counts = filtered_df["correct_answer"].value_counts().sort_index()
            ans_acc = filtered_df.groupby("correct_answer")["is_correct"].mean() * 100

            # Build combined table
            all_classes = sorted(set(ans_counts.index) | set(class_metrics.keys()))

            combined_table = pd.DataFrame(
                [
                    {
                        "ì„ íƒì§€": cls,
                        "ë¬¸í•­ ìˆ˜": int(ans_counts.get(cls, 0)),
                        "ë¹„ìœ¨ (%)": f"{ans_counts.get(cls, 0) / ans_counts.sum() * 100:.1f}%"
                        if ans_counts.sum() > 0
                        else "0.0%",
                        "ì •ë‹µë¥  (%)": f"{ans_acc.get(cls, 0):.1f}%",
                        "Precision": f"{class_metrics.get(cls, {}).get('precision', 0):.3f}",
                        "Recall": f"{class_metrics.get(cls, {}).get('recall', 0):.3f}",
                        "F1-Score": f"{class_metrics.get(cls, {}).get('f1', 0):.3f}",
                    }
                    for cls in all_classes
                ]
            )
            st.dataframe(combined_table, hide_index=True, use_container_width=True)
        else:
            st.warning("ì„±ëŠ¥ ì§€í‘œë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()

        # ------------------------------------------
        # Position Bias Analysis (ìœ„ì¹˜ í¸í–¥ ë¶„ì„)
        # ------------------------------------------
        st.subheader("ğŸ² Position Bias Analysis (ìœ„ì¹˜ í¸í–¥ ë¶„ì„)")
        st.caption(
            "ëª¨ë¸ì´ íŠ¹ì • ë²ˆí˜¸ë¥¼ ì„ í˜¸í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ì´ìƒì ìœ¼ë¡œëŠ” ì˜ˆì¸¡ ë¶„í¬ê°€ ì •ë‹µ ë¶„í¬ì™€ ìœ ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤."
        )

        if "correct_answer" in filtered_df.columns and "answer" in filtered_df.columns:
            pred_counts = filtered_df["answer"].value_counts().sort_index()
            true_counts = filtered_df["correct_answer"].value_counts().sort_index()

            # Ensure both series have the same index
            all_answers = sorted(set(pred_counts.index) | set(true_counts.index))
            pred_counts = pred_counts.reindex(all_answers, fill_value=0)
            true_counts = true_counts.reindex(all_answers, fill_value=0)

            # Grouped bar chart using Altair for direct comparison
            st.markdown("**ğŸ“Š ëª¨ë¸ ì˜ˆì¸¡ vs ì‹¤ì œ ì •ë‹µ ë¶„í¬ ë¹„êµ**")

            bias_chart_data = pd.DataFrame(
                {
                    "ë²ˆí˜¸": list(all_answers) * 2,
                    "ê°œìˆ˜": list(pred_counts.values) + list(true_counts.values),
                    "ìœ í˜•": ["ëª¨ë¸ ì˜ˆì¸¡"] * len(all_answers)
                    + ["ì‹¤ì œ ì •ë‹µ"] * len(all_answers),
                }
            )

            grouped_chart = (
                alt.Chart(bias_chart_data)
                .mark_bar()
                .encode(
                    x=alt.X("ë²ˆí˜¸:O", title="ì„ íƒì§€ ë²ˆí˜¸"),
                    y=alt.Y("ê°œìˆ˜:Q", title="ë¬¸í•­ ìˆ˜"),
                    color=alt.Color(
                        "ìœ í˜•:N",
                        scale=alt.Scale(
                            domain=["ëª¨ë¸ ì˜ˆì¸¡", "ì‹¤ì œ ì •ë‹µ"],
                            range=["#f97316", "#3b82f6"],
                        ),
                    ),
                    xOffset="ìœ í˜•:N",
                    tooltip=["ë²ˆí˜¸", "ìœ í˜•", "ê°œìˆ˜"],
                )
            )

            st.altair_chart(grouped_chart, use_container_width=True)

            # Calculate and display bias metrics
            pred_pct = pred_counts / pred_counts.sum() * 100
            true_pct = true_counts / true_counts.sum() * 100
            bias_diff = pred_pct - true_pct

            st.markdown("**í¸í–¥ ë¶„ì„ (ì˜ˆì¸¡ ë¹„ìœ¨ - ì •ë‹µ ë¹„ìœ¨)**")
            bias_display = pd.DataFrame(
                {
                    "ë²ˆí˜¸": all_answers,
                    "ì˜ˆì¸¡ ë¹„ìœ¨ (%)": [f"{v:.1f}%" for v in pred_pct.values],
                    "ì •ë‹µ ë¹„ìœ¨ (%)": [f"{v:.1f}%" for v in true_pct.values],
                    "í¸í–¥ (%)": [f"{v:+.1f}%" for v in bias_diff.values],
                }
            )
            st.dataframe(bias_display, hide_index=True)
        else:
            st.warning("ìœ„ì¹˜ í¸í–¥ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()

        # ------------------------------------------
        # Confusion Matrix (í˜¼ë™ í–‰ë ¬)
        # ------------------------------------------
        st.subheader("ğŸ”¢ Confusion Matrix (í˜¼ë™ í–‰ë ¬)")
        st.caption("ëª¨ë¸ ì˜ˆì¸¡ê³¼ ì‹¤ì œ ì •ë‹µ ê°„ì˜ ê´€ê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ëŒ€ê°ì„ ì´ ì •ë‹µì…ë‹ˆë‹¤.")

        if "correct_answer" in filtered_df.columns and "answer" in filtered_df.columns:
            confusion_data = (
                filtered_df.groupby(["correct_answer", "answer"])
                .size()
                .reset_index(name="count")
            )

            heatmap = (
                alt.Chart(confusion_data)
                .mark_rect()
                .encode(
                    x=alt.X("answer:O", title="ì˜ˆì¸¡ (Predicted)"),
                    y=alt.Y(
                        "correct_answer:O", title="ì •ë‹µ (Actual)", sort="ascending"
                    ),
                    color=alt.Color(
                        "count:Q", scale=alt.Scale(scheme="oranges"), title="ë¬¸í•­ ìˆ˜"
                    ),
                    tooltip=[
                        alt.Tooltip("correct_answer:O", title="ì •ë‹µ"),
                        alt.Tooltip("answer:O", title="ì˜ˆì¸¡"),
                        alt.Tooltip("count:Q", title="ë¬¸í•­ ìˆ˜"),
                    ],
                )
                .properties(width=400, height=400, title="Confusion Matrix")
            )

            # Add text labels on heatmap
            text = heatmap.mark_text(baseline="middle").encode(
                text="count:Q",
                color=alt.condition(
                    alt.datum.count > confusion_data["count"].max() / 2,
                    alt.value("white"),
                    alt.value("black"),
                ),
            )

            st.altair_chart(heatmap + text, use_container_width=False)
        else:
            st.warning("Confusion Matrixë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()

        # ------------------------------------------
        # ì…ë ¥ ê¸¸ì´ êµ¬ê°„ë³„ ë¶„ì„
        # ------------------------------------------
        st.subheader("ğŸ“ ì…ë ¥ ê¸¸ì´ êµ¬ê°„ë³„ ë¶„ì„")

        if "input_length" in filtered_df.columns and not filtered_df.empty:
            maxbins = 20  # íˆìŠ¤í† ê·¸ë¨ê³¼ í‘œì—ì„œ ê³µí†µ ì‚¬ìš©

            # ==============================
            # 1) ì •ë‹µ / ì˜¤ë‹µ íˆìŠ¤í† ê·¸ë¨
            # ==============================
            chart_data = filtered_df[["input_length", "is_correct"]].copy()
            chart_data["status"] = chart_data["is_correct"].map(
                {True: "ì •ë‹µ (Correct)", False: "ì˜¤ë‹µ (Incorrect)"}
            )

            hist_chart = (
                alt.Chart(chart_data)
                .mark_bar()
                .encode(
                    x=alt.X(
                        "input_length:Q",
                        bin=alt.Bin(maxbins=maxbins),
                        title="ì…ë ¥ ê¸¸ì´ (ê¸€ì ìˆ˜)",
                    ),
                    y=alt.Y("count():Q", title="ë¬¸í•­ ìˆ˜"),
                    color=alt.Color(
                        "status:N",
                        scale=alt.Scale(
                            domain=["ì •ë‹µ (Correct)", "ì˜¤ë‹µ (Incorrect)"],
                            range=["#3b82f6", "#ef4444"],
                        ),
                        title="ì •ë‹µ ì—¬ë¶€",
                    ),
                    tooltip=[
                        alt.Tooltip("status:N", title="ì •ë‹µ ì—¬ë¶€"),
                        alt.Tooltip("count():Q", title="ë¬¸í•­ ìˆ˜"),
                    ],
                )
                .properties(title="ì…ë ¥ ê¸¸ì´ ë³„ ì •ë‹µ/ì˜¤ë‹µ ë¶„í¬")
                .interactive()
            )

            st.altair_chart(hist_chart, use_container_width=True)

            st.caption(
                "â€» íˆìŠ¤í† ê·¸ë¨ì€ ì…ë ¥ ê¸¸ì´ ë¶„í¬ë¥¼ ë³´ì—¬ì£¼ë©°, êµ¬ê°„ë³„ ì •ë‹µë¥ ì˜ ì‹ ë¢°ë„ëŠ” "
                "ì•„ë˜ í‘œì˜ ë¬¸í•­ ìˆ˜ë¥¼ í•¨ê»˜ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤."
            )

            # ==============================
            # 2) ì…ë ¥ ê¸¸ì´ êµ¬ê°„ë³„ ì •ë‹µë¥  í‘œ (0~100, 100~200 ...)
            # ==============================
            bin_step = 100

            tmp = filtered_df[["input_length", "is_correct"]].copy()

            # êµ¬ê°„ ê²½ê³„ ìƒì„±
            min_len = int(tmp["input_length"].min() // bin_step * bin_step)
            max_len = int((tmp["input_length"].max() // bin_step + 1) * bin_step)
            bins = list(range(min_len, max_len + bin_step, bin_step))

            # êµ¬ê°„ ë‚˜ëˆ„ê¸°
            tmp["length_bin"] = pd.cut(
                tmp["input_length"],
                bins=bins,
                right=False,  # [0,100), [100,200) í˜•íƒœ
            )

            # ì§‘ê³„
            bin_table = (
                tmp.groupby("length_bin", observed=True)
                .agg(
                    ë¬¸í•­ìˆ˜=("is_correct", "count"),
                    í‰ê· ê¸¸ì´=("input_length", "mean"),
                    ì •ë‹µìˆ˜=("is_correct", "sum"),
                    ì •ë‹µë¥ =("is_correct", "mean"),
                )
                .reset_index()
            )

            # ğŸ”¹ êµ¬ê°„ ë¼ë²¨ì„ "0~100" í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            bin_table["ê¸¸ì´ êµ¬ê°„"] = bin_table["length_bin"].apply(
                lambda x: f"{int(x.left)}~{int(x.right)}"
            )

            # í¬ë§· ì •ë¦¬
            bin_table["ì •ë‹µë¥ (%)"] = (bin_table["ì •ë‹µë¥ "] * 100).round(2)
            bin_table["í‰ê· ê¸¸ì´"] = bin_table["í‰ê· ê¸¸ì´"].round(0).astype(int)

            bin_table = bin_table[
                ["ê¸¸ì´ êµ¬ê°„", "ë¬¸í•­ìˆ˜", "í‰ê· ê¸¸ì´", "ì •ë‹µìˆ˜", "ì •ë‹µë¥ (%)"]
            ]

            # ì •ë ¬ ì˜µì…˜
            sort_by = st.radio(
                "êµ¬ê°„ë³„ ì •ë‹µë¥  í‘œ ì •ë ¬ ê¸°ì¤€",
                ["ê¸¸ì´ êµ¬ê°„ ìˆœ", "ì •ë‹µë¥  ë†’ì€ ìˆœ", "ì •ë‹µë¥  ë‚®ì€ ìˆœ"],
                horizontal=True,
            )

            if sort_by == "ì •ë‹µë¥  ë†’ì€ ìˆœ":
                bin_table = bin_table.sort_values("ì •ë‹µë¥ (%)", ascending=False)
            elif sort_by == "ì •ë‹µë¥  ë‚®ì€ ìˆœ":
                bin_table = bin_table.sort_values("ì •ë‹µë¥ (%)", ascending=True)

            st.dataframe(bin_table, use_container_width=True, hide_index=True)

        else:
            st.info("ì…ë ¥ ê¸¸ì´ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()

        # ------------------------------------------
        # ë°ì´í„° ë¼ë²¨ ë¶„í¬ ë° ì •ë‹µë¥ 
        # ------------------------------------------
        st.subheader("ğŸ·ï¸ ë°ì´í„° ë¼ë²¨ ë¶„í¬ ë° ì •ë‹µë¥ ")

        if potential_cats:
            selected_cat = st.selectbox("ë¶„ì„í•  ë¼ë²¨(Feature) ì„ íƒ", potential_cats)

            if selected_cat:
                row_c1, row_c2 = st.columns(2)

                with row_c1:
                    st.markdown(f"**'{selected_cat}' ë¶„í¬ (ë¬¸í•­ ìˆ˜)**")
                    dist_counts = filtered_df[selected_cat].value_counts().reset_index()
                    dist_counts.columns = [selected_cat, "ë¬¸í•­ ìˆ˜"]

                    dist_chart = (
                        alt.Chart(dist_counts)
                        .mark_bar(color="#3b82f6")
                        .encode(
                            x=alt.X(
                                f"{selected_cat}:N",
                                title=None,
                                axis=alt.Axis(labelAngle=0),
                            ),
                            y=alt.Y("ë¬¸í•­ ìˆ˜:Q", title="ë¬¸í•­ ìˆ˜"),
                            tooltip=[selected_cat, "ë¬¸í•­ ìˆ˜"],
                        )
                        .properties(height=300)
                    )
                    st.altair_chart(dist_chart, use_container_width=True)

                with row_c2:
                    st.markdown(f"**'{selected_cat}'ë³„ ì •ë‹µë¥  (%)**")
                    cat_acc = (
                        filtered_df.groupby(selected_cat)["is_correct"].mean() * 100
                    )
                    cat_acc_df = cat_acc.reset_index()
                    cat_acc_df.columns = [selected_cat, "ì •ë‹µë¥  (%)"]

                    acc_chart = (
                        alt.Chart(cat_acc_df)
                        .mark_bar(color="#f97316")
                        .encode(
                            x=alt.X(
                                f"{selected_cat}:N",
                                title=None,
                                axis=alt.Axis(labelAngle=0),
                            ),
                            y=alt.Y("ì •ë‹µë¥  (%):Q", title="ì •ë‹µë¥  (%)"),
                            tooltip=[
                                selected_cat,
                                alt.Tooltip("ì •ë‹µë¥  (%):Q", format=".1f"),
                            ],
                        )
                        .properties(height=300)
                    )
                    st.altair_chart(acc_chart, use_container_width=True)
        else:
            st.info(
                "ë¶„ì„í•  ì¶”ê°€ì ì¸ ë°ì´í„° ë¼ë²¨(ì¹´í…Œê³ ë¦¬)ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ê³ ìœ ê°’ 50ê°œ ë¯¸ë§Œì¸ ì»¬ëŸ¼ ì—†ìŒ)"
            )

    # ==========================================
    # íƒ­ 2: ëª¨ë¸ ì˜¤ë‹µ ë¶„ì„
    # ==========================================
    with tab_error_analysis:
        st.header("ì˜¤ë‹µ ë¬¸ì œ ìƒì„¸ í™•ì¸")

        # ì˜¤ë‹µë§Œ í•„í„°ë§
        error_df = filtered_df[~filtered_df["is_correct"]]

        st.markdown(
            f"**í˜„ì¬ í•„í„° ê¸°ì¤€ ì˜¤ë‹µ ë¬¸í•­ ìˆ˜**: {len(error_df)} / {len(filtered_df)}"
        )

        # ------------------------------------------
        # CSV Export
        # ------------------------------------------
        if len(error_df) > 0:
            col_export1, col_export2 = st.columns([1, 4])
            with col_export1:
                csv_data = error_df.to_csv(index=False).encode("utf-8")
                st.download_button(
                    label="ğŸ“¥ ì˜¤ë‹µ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv_data,
                    file_name="error_analysis.csv",
                    mime="text/csv",
                )

        if len(error_df) == 0:
            st.success("ğŸ‰ í•´ë‹¹ ì¡°ê±´ì—ì„œ í‹€ë¦° ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤!")
            return

        st.divider()

        # ------------------------------------------
        # Pagination
        # ------------------------------------------
        st.subheader("ğŸ“„ ì˜¤ë‹µ ëª©ë¡")

        items_per_page = st.slider(
            "í˜ì´ì§€ë‹¹ ë¬¸í•­ ìˆ˜", min_value=5, max_value=50, value=10
        )
        total_pages = max(1, (len(error_df) - 1) // items_per_page + 1)
        page_num = st.number_input(
            "í˜ì´ì§€", min_value=1, max_value=total_pages, value=1
        )

        start_idx = (page_num - 1) * items_per_page
        end_idx = start_idx + items_per_page
        paginated_df = error_df.iloc[start_idx:end_idx]

        st.caption(f"í˜ì´ì§€ {page_num} / {total_pages} (ì´ {len(error_df)}ê°œ ì˜¤ë‹µ)")

        # ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
        for _, row in paginated_df.iterrows():
            with st.expander(f"âŒ [ì˜¤ë‹µ] ID: {row['id']}"):
                st.markdown("### ì§€ë¬¸ (Paragraph)")
                st.info(row["paragraph"])

                st.markdown(f"### ì§ˆë¬¸: {row['question']}")

                try:
                    choices = row["choices"]
                    correct_idx = int(row["correct_answer"]) - 1
                    pred_idx = int(row["answer"]) - 1
                except (ValueError, TypeError):
                    st.warning("ì„ íƒì§€/ì •ë‹µ íŒŒì‹± ì˜¤ë¥˜")
                    continue

                for i, choice in enumerate(choices):
                    prefix = ""
                    color = "black"
                    bg_color = "transparent"

                    if i == correct_idx:
                        prefix += "âœ… (ì •ë‹µ) "
                        color = "green"
                        bg_color = "#e6ffe6"

                    if i == pred_idx:
                        prefix += "ğŸ¤– (ì˜ˆì¸¡) "
                        if i != correct_idx:
                            color = "red"
                            bg_color = "#ffe6e6"

                    st.markdown(
                        f"<div style='background-color: {bg_color}; padding: 5px; border-radius: 5px; color: {color};'>"
                        f"{i + 1}. {prefix}{choice}</div>",
                        unsafe_allow_html=True,
                    )

                st.divider()
                st.markdown("**ë©”íƒ€ë°ì´í„°**")
                meta_cols = [
                    col
                    for col in row.index
                    if col
                    not in [
                        "paragraph",
                        "problems",
                        "question",
                        "choices",
                        "is_correct",
                        "input_length",
                    ]
                ]
                st.json(row[meta_cols].to_dict())

    # ==========================================
    # íƒ­ 3: ëª¨ë¸ ë¹„êµ (ì¡°ê±´ë¶€)
    # ==========================================
    if enable_comparison and merged_df_2 is not None:
        with tab_comparison:
            st.header("ğŸ”„ ëª¨ë¸ ë¹„êµ ë¶„ì„")

            # í•„í„°ë§ëœ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë¹„êµ
            filtered_ids = set(filtered_df["id"].tolist())
            filtered_df_2_comp = merged_df_2[merged_df_2["id"].isin(filtered_ids)]

            model1_correct = set(filtered_df[filtered_df["is_correct"]]["id"].tolist())
            model2_correct = set(
                filtered_df_2_comp[filtered_df_2_comp["is_correct_2"]]["id"].tolist()
            )
            all_ids = filtered_ids

            # Calculate sets
            both_correct = model1_correct & model2_correct
            only_model1_correct = model1_correct - model2_correct
            only_model2_correct = model2_correct - model1_correct
            both_wrong = all_ids - model1_correct - model2_correct

            # Summary metrics
            st.subheader("ğŸ“Š ë¹„êµ ìš”ì•½")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("ë‘˜ ë‹¤ ì •ë‹µ", len(both_correct))
            col2.metric("ëª¨ë¸ 1ë§Œ ì •ë‹µ", len(only_model1_correct))
            col3.metric("ëª¨ë¸ 2ë§Œ ì •ë‹µ", len(only_model2_correct))
            col4.metric("ë‘˜ ë‹¤ ì˜¤ë‹µ", len(both_wrong))

            st.divider()

            # Accuracy comparison
            st.subheader("ğŸ“ˆ ì •í™•ë„ ë¹„êµ")
            acc_model1 = (
                len(model1_correct) / len(all_ids) * 100 if len(all_ids) > 0 else 0
            )
            acc_model2 = (
                len(model2_correct) / len(all_ids) * 100 if len(all_ids) > 0 else 0
            )

            acc_comparison = pd.DataFrame(
                {
                    "ëª¨ë¸": ["ëª¨ë¸ 1", "ëª¨ë¸ 2"],
                    "ì •ë‹µ ìˆ˜": [len(model1_correct), len(model2_correct)],
                    "ì •í™•ë„ (%)": [f"{acc_model1:.2f}%", f"{acc_model2:.2f}%"],
                }
            )
            st.dataframe(acc_comparison, hide_index=True, use_container_width=True)

            st.divider()

            # ------------------------------------------
            # ì…ë ¥ ê¸¸ì´ë³„ ëª¨ë¸ ì •ë‹µë¥  ë¹„êµ
            # ------------------------------------------
            st.subheader("ğŸ“ ì…ë ¥ ê¸¸ì´ë³„ ëª¨ë¸ ì •ë‹µë¥  ë¹„êµ")
            st.caption("ì…ë ¥ ê¸¸ì´ êµ¬ê°„ë³„ë¡œ ë‘ ëª¨ë¸ì˜ ì •ë‹µë¥ ì„ ë¹„êµí•©ë‹ˆë‹¤.")

            if "input_length" in filtered_df.columns and not filtered_df.empty:
                bin_step = 100

                # ëª¨ë¸ 2ì— input_length ì¶”ê°€
                filtered_df_2 = merged_df_2[
                    merged_df_2["id"].isin(filtered_df["id"])
                ].copy()
                filtered_df_2["input_length"] = (
                    filtered_df.set_index("id")["input_length"]
                    .reindex(filtered_df_2["id"])
                    .values
                )

                # êµ¬ê°„ ê²½ê³„ ìƒì„±
                min_len = int(filtered_df["input_length"].min() // bin_step * bin_step)
                max_len = int(
                    (filtered_df["input_length"].max() // bin_step + 1) * bin_step
                )
                bins = list(range(min_len, max_len + bin_step, bin_step))

                # ëª¨ë¸ 1 êµ¬ê°„ë³„ ì •ë‹µë¥ 
                tmp1 = filtered_df[["input_length", "is_correct"]].copy()
                tmp1["length_bin"] = pd.cut(
                    tmp1["input_length"], bins=bins, right=False
                )
                bin_acc_model1 = (
                    tmp1.groupby("length_bin", observed=True)["is_correct"].mean() * 100
                )
                bin_count = tmp1.groupby("length_bin", observed=True).size()

                # ëª¨ë¸ 2 êµ¬ê°„ë³„ ì •ë‹µë¥ 
                tmp2 = filtered_df_2[["input_length", "is_correct_2"]].copy()
                tmp2["length_bin"] = pd.cut(
                    tmp2["input_length"], bins=bins, right=False
                )
                bin_acc_model2 = (
                    tmp2.groupby("length_bin", observed=True)["is_correct_2"].mean()
                    * 100
                )

                # Line Chart with Points
                all_bins = sorted(set(bin_acc_model1.index) | set(bin_acc_model2.index))
                bin_labels = [f"{int(b.left)}~{int(b.right)}" for b in all_bins]
                # xì¶•ì— êµ¬ê°„ ì¤‘ê°„ê°’ ì‚¬ìš© (ì •ë ¬ìš©)
                bin_mid = [(b.left + b.right) / 2 for b in all_bins]

                length_chart_data = pd.DataFrame(
                    {
                        "ê¸¸ì´ êµ¬ê°„": bin_labels * 2,
                        "êµ¬ê°„ ì¤‘ê°„ê°’": bin_mid * 2,
                        "ì •ë‹µë¥  (%)": list(
                            bin_acc_model1.reindex(all_bins, fill_value=0)
                        )
                        + list(bin_acc_model2.reindex(all_bins, fill_value=0)),
                        "ëª¨ë¸": ["ëª¨ë¸ 1"] * len(all_bins) + ["ëª¨ë¸ 2"] * len(all_bins),
                    }
                )

                # Line + Point chart
                base = alt.Chart(length_chart_data).encode(
                    x=alt.X(
                        "êµ¬ê°„ ì¤‘ê°„ê°’:Q",
                        title="ì…ë ¥ ê¸¸ì´",
                        scale=alt.Scale(domain=[min(bin_mid) - 50, max(bin_mid) + 50]),
                    ),
                    y=alt.Y(
                        "ì •ë‹µë¥  (%):Q",
                        title="ì •ë‹µë¥  (%)",
                        scale=alt.Scale(domain=[0, 100]),
                    ),
                    color=alt.Color(
                        "ëª¨ë¸:N",
                        scale=alt.Scale(
                            domain=["ëª¨ë¸ 1", "ëª¨ë¸ 2"], range=["#f97316", "#9ca3af"]
                        ),
                        legend=alt.Legend(title="ëª¨ë¸"),
                    ),
                    tooltip=[
                        "ê¸¸ì´ êµ¬ê°„",
                        "ëª¨ë¸",
                        alt.Tooltip("ì •ë‹µë¥  (%):Q", format=".1f"),
                    ],
                )

                line = base.mark_line(strokeWidth=3)
                points = base.mark_point(size=100, filled=True)

                length_line_chart = (line + points).properties(
                    title="ì…ë ¥ ê¸¸ì´ êµ¬ê°„ë³„ ëª¨ë¸ ì •ë‹µë¥  ë¹„êµ",
                    height=350,
                )

                st.altair_chart(length_line_chart, use_container_width=True)

                # ë¹„êµ í…Œì´ë¸”
                st.markdown("**ğŸ“‹ ì…ë ¥ ê¸¸ì´ë³„ ì •ë‹µë¥  ë¹„êµ í…Œì´ë¸”**")
                length_comparison_table = pd.DataFrame(
                    {
                        "ê¸¸ì´ êµ¬ê°„": bin_labels,
                        "ë¬¸í•­ ìˆ˜": [bin_count.get(b, 0) for b in all_bins],
                        "ëª¨ë¸ 1 ì •ë‹µë¥ ": [
                            f"{bin_acc_model1.get(b, 0):.1f}%" for b in all_bins
                        ],
                        "ëª¨ë¸ 2 ì •ë‹µë¥ ": [
                            f"{bin_acc_model2.get(b, 0):.1f}%" for b in all_bins
                        ],
                        "ì°¨ì´ (Î”)": [
                            f"{bin_acc_model1.get(b, 0) - bin_acc_model2.get(b, 0):+.1f}%"
                            for b in all_bins
                        ],
                    }
                )
                st.dataframe(
                    length_comparison_table, hide_index=True, use_container_width=True
                )
            else:
                st.info("ì…ë ¥ ê¸¸ì´ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            st.divider()

            # ------------------------------------------
            # ë¼ë²¨ë³„ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
            # ------------------------------------------
            st.subheader("ğŸ·ï¸ ë¼ë²¨ë³„ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
            st.caption("ê° ë¼ë²¨(ì¹´í…Œê³ ë¦¬)ì—ì„œ ë‘ ëª¨ë¸ì˜ ì •ë‹µë¥ ì„ ë¹„êµí•©ë‹ˆë‹¤.")

            if potential_cats:
                selected_cat_comp = st.selectbox(
                    "ë¶„ì„í•  ë¼ë²¨(Feature) ì„ íƒ",
                    potential_cats,
                    key="comparison_cat_select",
                )

                if selected_cat_comp:
                    # ëª¨ë¸ 1, ëª¨ë¸ 2 ì •ë‹µë¥  ê³„ì‚°
                    cat_acc_model1 = (
                        filtered_df.groupby(selected_cat_comp)["is_correct"].mean()
                        * 100
                    )
                    cat_count = filtered_df.groupby(selected_cat_comp).size()

                    # ëª¨ë¸ 2 ì •ë‹µë¥  ê³„ì‚°
                    filtered_df_2 = merged_df_2[
                        merged_df_2["id"].isin(filtered_df["id"])
                    ]
                    cat_acc_model2 = (
                        filtered_df_2.groupby(selected_cat_comp)["is_correct_2"].mean()
                        * 100
                    )

                    # Grouped Bar Chart (Altair)
                    all_labels = sorted(
                        set(cat_acc_model1.index) | set(cat_acc_model2.index)
                    )
                    chart_data = pd.DataFrame(
                        {
                            "ë¼ë²¨": list(all_labels) * 2,
                            "ì •ë‹µë¥  (%)": list(
                                cat_acc_model1.reindex(all_labels, fill_value=0)
                            )
                            + list(cat_acc_model2.reindex(all_labels, fill_value=0)),
                            "ëª¨ë¸": ["ëª¨ë¸ 1"] * len(all_labels)
                            + ["ëª¨ë¸ 2"] * len(all_labels),
                        }
                    )

                    grouped_chart = (
                        alt.Chart(chart_data)
                        .mark_bar()
                        .encode(
                            x=alt.X("ë¼ë²¨:N", title=selected_cat_comp, sort=all_labels),
                            y=alt.Y("ì •ë‹µë¥  (%):Q", title="ì •ë‹µë¥  (%)"),
                            color=alt.Color(
                                "ëª¨ë¸:N",
                                scale=alt.Scale(
                                    domain=["ëª¨ë¸ 1", "ëª¨ë¸ 2"],
                                    range=["#f97316", "#9ca3af"],
                                ),
                            ),
                            xOffset="ëª¨ë¸:N",
                            tooltip=[
                                "ë¼ë²¨",
                                "ëª¨ë¸",
                                alt.Tooltip("ì •ë‹µë¥  (%):Q", format=".1f"),
                            ],
                        )
                        .properties(title=f"'{selected_cat_comp}'ë³„ ëª¨ë¸ ì •ë‹µë¥  ë¹„êµ")
                    )

                    st.altair_chart(grouped_chart, use_container_width=True)

                    # ë¹„êµ í…Œì´ë¸”
                    st.markdown("**ğŸ“‹ ë¼ë²¨ë³„ ì •ë‹µë¥  ë¹„êµ í…Œì´ë¸”**")
                    comparison_table = pd.DataFrame(
                        {
                            "ë¼ë²¨": all_labels,
                            "ë¬¸í•­ ìˆ˜": [cat_count.get(lbl, 0) for lbl in all_labels],
                            "ëª¨ë¸ 1 ì •ë‹µë¥ ": [
                                f"{cat_acc_model1.get(lbl, 0):.1f}%"
                                for lbl in all_labels
                            ],
                            "ëª¨ë¸ 2 ì •ë‹µë¥ ": [
                                f"{cat_acc_model2.get(lbl, 0):.1f}%"
                                for lbl in all_labels
                            ],
                            "ì°¨ì´ (Î”)": [
                                f"{cat_acc_model1.get(lbl, 0) - cat_acc_model2.get(lbl, 0):+.1f}%"
                                for lbl in all_labels
                            ],
                        }
                    )
                    st.dataframe(
                        comparison_table, hide_index=True, use_container_width=True
                    )
            else:
                st.info(
                    "ë¶„ì„í•  ì¶”ê°€ì ì¸ ë°ì´í„° ë¼ë²¨(ì¹´í…Œê³ ë¦¬)ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ê³ ìœ ê°’ 50ê°œ ë¯¸ë§Œì¸ ì»¬ëŸ¼ ì—†ìŒ)"
                )

            st.divider()

            # ------------------------------------------
            # ëª¨ë¸ ê°„ ì°¨ì´ ë¶„ì„
            # ------------------------------------------
            st.subheader("ğŸ” ëª¨ë¸ ê°„ ì°¨ì´ ë¶„ì„")

            diff_type = st.selectbox(
                "ë³´ê¸° ì˜µì…˜",
                ["ëª¨ë¸ 1ë§Œ ì •ë‹µì¸ ë¬¸ì œ", "ëª¨ë¸ 2ë§Œ ì •ë‹µì¸ ë¬¸ì œ", "ë‘˜ ë‹¤ ì˜¤ë‹µì¸ ë¬¸ì œ"],
            )

            if diff_type == "ëª¨ë¸ 1ë§Œ ì •ë‹µì¸ ë¬¸ì œ":
                diff_ids = list(only_model1_correct)
            elif diff_type == "ëª¨ë¸ 2ë§Œ ì •ë‹µì¸ ë¬¸ì œ":
                diff_ids = list(only_model2_correct)
            else:
                diff_ids = list(both_wrong)

            st.markdown(f"**{diff_type}**: {len(diff_ids)}ê°œ")

            if diff_ids:
                diff_df = merged_df[merged_df["id"].isin(diff_ids)]

                # Pagination
                items_per_page_diff = st.slider(
                    "í˜ì´ì§€ë‹¹ ë¬¸í•­ ìˆ˜ (ë¹„êµ)",
                    min_value=5,
                    max_value=50,
                    value=10,
                    key="diff_per_page",
                )
                total_pages_diff = max(1, (len(diff_df) - 1) // items_per_page_diff + 1)
                page_num_diff = st.number_input(
                    "í˜ì´ì§€ (ë¹„êµ)",
                    min_value=1,
                    max_value=total_pages_diff,
                    value=1,
                    key="diff_page",
                )

                start_idx_diff = (page_num_diff - 1) * items_per_page_diff
                end_idx_diff = start_idx_diff + items_per_page_diff
                paginated_diff_df = diff_df.iloc[start_idx_diff:end_idx_diff]

                st.caption(
                    f"í˜ì´ì§€ {page_num_diff} / {total_pages_diff} (ì´ {len(diff_df)}ê°œ ì°¨ì´)"
                )

                for _, row in paginated_diff_df.iterrows():
                    with st.expander(f"ID: {row['id']}"):
                        st.info(
                            row["paragraph"][:200] + "..."
                            if len(str(row["paragraph"])) > 200
                            else row["paragraph"]
                        )
                        st.markdown(f"**ì§ˆë¬¸**: {row['question']}")

                        # Choices display
                        try:
                            choices = row["choices"]
                            correct_idx = int(row["correct_answer"]) - 1
                            pred1_idx = int(row["answer"]) - 1

                            # Model 2 prediction lookup
                            row2 = merged_df_2[merged_df_2["id"] == row["id"]].iloc[0]
                            pred2_idx = int(row2["answer"]) - 1
                        except (ValueError, TypeError, IndexError):
                            st.warning("ì„ íƒì§€/ì •ë‹µ íŒŒì‹± ì˜¤ë¥˜")
                            continue

                        st.markdown(
                            f"**ì •ë‹µ**: {row['correct_answer']} | **ëª¨ë¸ 1 ì˜ˆì¸¡**: {row['answer']} | **ëª¨ë¸ 2 ì˜ˆì¸¡**: {row2['answer']}"
                        )

                        for i, choice in enumerate(choices):
                            prefix = ""
                            color = "black"
                            bg_color = "transparent"

                            if i == correct_idx:
                                prefix += "âœ… (ì •ë‹µ) "
                                color = "green"
                                bg_color = "#e6ffe6"

                            pred_info = []
                            if i == pred1_idx:
                                pred_info.append("ğŸ¤–1")
                            if i == pred2_idx:
                                pred_info.append("ğŸ¤–2")

                            if pred_info:
                                prefix += f"{' & '.join(pred_info)} (ì˜ˆì¸¡) "
                                if i != correct_idx:
                                    color = "red"
                                    bg_color = "#ffe6e6"

                            st.markdown(
                                f"<div style='background-color: {bg_color}; padding: 5px; border-radius: 5px; color: {color};'>"
                                f"{i + 1}. {prefix}{choice}</div>",
                                unsafe_allow_html=True,
                            )


if __name__ == "__main__":
    main()
