# -------------------------------------------- #
#                    학습 설정                   #
# -------------------------------------------- #
train:
  # 모델 설정
  model:
    name: "unsloth/Qwen2.5-32B-Instruct-bnb-4bit"

  # 데이터 설정
  data:
    train_path: "data/train.csv"
    prompt_style: "v1"
    eval_ratio: 0.1

  # 학습 하이퍼파라미터
  training:
    output_dir: "outputs"
    max_seq_length: 4096
    batch_size: 16
    epochs: 3
    learning_rate: 2.0e-5
    weight_decay: 0.01
    logging_steps: 1
    logging_strategy: "epoch"  # "steps", "epoch", "no"
    seed: 42

  # LoRA 설정
  lora:
    r: 6
    alpha: 8
    dropout: 0.05

# -------------------------------------------- #
#                    추론 설정                   #
# -------------------------------------------- #

inference:
  # 모델 설정
  model:
    checkpoint_path: "unsloth/Qwen2.5-32B-Instruct-bnb-4bit"   #실제 경로 or Hugging Face 모델명

  # 데이터 설정
  data:
    test_path: "data/test.csv"
    prompt_style: "v1"

  # Only use FastLanguage Model
  FLM:
    max_seq_length: 4096

  # 원격 서버 사용 여부
  use_remote: True

  # 출력 설정
  output:
    path: "outputs/output.csv"

  # Pipeline 설정
  pipeline:
    max_retrieval_context_chars: 4000  # 검색된 문서들을 결합한 컨텍스트의 최대 문자 수
    max_paragraph_chars_for_planner: 600  # Planner 사용 최대 paragraph 길이 (이하일 때만 planning 수행)
    query_plan_log_path: "log/query_decompositions.jsonl"  # Query plan 로그 경로

  # Planner LLM 설정
  planner_llm:
    temperature: 1.0  # 생성 다양성

# -------------------------------------------- #
#                   wandb 설정                  #
# -------------------------------------------- #
wandb:
  entity: "TeamAtoI"
  project: "CSAT"
  run_name: test # 자동생성, 이름 지정도 가능

# -------------------------------------------- #
#                     SCORE                    #
# -------------------------------------------- #

score:
  # macro-f1
  local: 0
  public: 0
